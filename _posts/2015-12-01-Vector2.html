<html lang="en-US">
  <head>
    <title>Lab41</title>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <script src="https://use.typekit.net/ymx5ojz.js"></script>
    <script>try{Typekit.load({ async: true });}catch(e){}</script>
    <link rel="stylesheet" href="https://www.lab41.org/wp-content/themes/wp20150917/style.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="https://www.lab41.org/wp-content/themes/wp20150917/includes/blog/kroneckerapp.js"></script>

    <link rel="stylesheet" href="https://www.lab41.org/wp-content/themes/wp20150917/includes/blog/kronecker.css">

    <link rel="alternate" type="application/rss+xml" title="Lab41 &raquo; Anything2Vec Comments Feed" href="https://www.lab41.org/anything2vec/feed/" />
		<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/72x72\/","ext":".png","source":{"concatemoji":"https:\/\/www.lab41.org\/wp-includes\/js\/wp-emoji-release.min.js?ver=4.3.2"}};
			!function(a,b,c){function d(a){var c=b.createElement("canvas"),d=c.getContext&&c.getContext("2d");return d&&d.fillText?(d.textBaseline="top",d.font="600 32px Arial","flag"===a?(d.fillText(String.fromCharCode(55356,56812,55356,56807),0,0),c.toDataURL().length>3e3):(d.fillText(String.fromCharCode(55357,56835),0,0),0!==d.getImageData(16,16,1,1).data[0])):!1}function e(a){var c=b.createElement("script");c.src=a,c.type="text/javascript",b.getElementsByTagName("head")[0].appendChild(c)}var f,g;c.supports={simple:d("simple"),flag:d("flag")},c.DOMReady=!1,c.readyCallback=function(){c.DOMReady=!0},c.supports.simple&&c.supports.flag||(g=function(){c.readyCallback()},b.addEventListener?(b.addEventListener("DOMContentLoaded",g,!1),a.addEventListener("load",g,!1)):(a.attachEvent("onload",g),b.attachEvent("onreadystatechange",function(){"complete"===b.readyState&&c.readyCallback()})),f=c.source||{},f.concatemoji?e(f.concatemoji):f.wpemoji&&f.twemoji&&(e(f.twemoji),e(f.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
		<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
<link rel='stylesheet' id='open-sans-css'  href='https://fonts.googleapis.com/css?family=Open+Sans%3A300italic%2C400italic%2C600italic%2C300%2C400%2C600&#038;subset=latin%2Clatin-ext&#038;ver=4.3.2' type='text/css' media='all' />
<link rel='stylesheet' id='dashicons-css'  href='https://www.lab41.org/wp-includes/css/dashicons.min.css?ver=4.3.2' type='text/css' media='all' />
<link rel='stylesheet' id='admin-bar-css'  href='https://www.lab41.org/wp-includes/css/admin-bar.min.css?ver=4.3.2' type='text/css' media='all' />
<link rel='stylesheet' id='crayon-css'  href='https://www.lab41.org/wp-content/plugins/crayon-syntax-highlighter/css/min/crayon.min.css?ver=2.7.1' type='text/css' media='all' />
<link rel='stylesheet' id='contact-form-7-css'  href='https://www.lab41.org/wp-content/plugins/contact-form-7/includes/css/styles.css?ver=4.3' type='text/css' media='all' />
<script type='text/javascript'>
/* <![CDATA[ */
window.CKEDITOR_BASEPATH = "https://www.lab41.org/wp-content/plugins/ckeditor-for-wordpress/ckeditor/";
var ckeditorSettings = { "textarea_id": "comment", "pluginPath": "https:\/\/www.lab41.org\/wp-content\/plugins\/ckeditor-for-wordpress\/", "autostart": true, "excerpt_state": false, "qtransEnabled": false, "outputFormat": { "indent": true, "breakBeforeOpen": true, "breakAfterOpen": true, "breakBeforeClose": true, "breakAfterClose": true }, "configuration": { "height": "160px", "skin": "moono", "scayt_autoStartup": false, "entities": true, "entities_greek": true, "entities_latin": true, "toolbar": "WordpressBasic", "templates_files": [ "https:\/\/www.lab41.org\/wp-content\/plugins\/ckeditor-for-wordpress\/ckeditor.templates.js" ], "stylesCombo_stylesSet": "wordpress:https:\/\/www.lab41.org\/wp-content\/plugins\/ckeditor-for-wordpress\/ckeditor.styles.js", "allowedContent": true, "customConfig": "https:\/\/www.lab41.org\/wp-content\/plugins\/ckeditor-for-wordpress\/ckeditor.config.js" }, "externalPlugins": [  ], "additionalButtons": [  ] }
/* ]]> */
</script><style type="text/css">
			#content table.cke_editor { margin:0; }
			#content table.cke_editor tr td { padding:0;border:0; }
		</style><script type='text/javascript' src='https://www.lab41.org/wp-includes/js/jquery/jquery.js?ver=1.11.3'></script>
<script type='text/javascript' src='https://www.lab41.org/wp-includes/js/jquery/jquery-migrate.min.js?ver=1.2.1'></script>
<script type='text/javascript'>
/* <![CDATA[ */
var CrayonSyntaxSettings = {"version":"2.7.1","is_admin":"0","ajaxurl":"https:\/\/www.lab41.org\/wp-admin\/admin-ajax.php","prefix":"crayon-","setting":"crayon-setting","selected":"crayon-setting-selected","changed":"crayon-setting-changed","special":"crayon-setting-special","orig_value":"data-orig-value","debug":""};
var CrayonSyntaxStrings = {"copy":"Press %s to Copy, %s to Paste","minimize":"Click To Expand Code"};
/* ]]> */
</script>
<script type='text/javascript' src='https://www.lab41.org/wp-content/plugins/crayon-syntax-highlighter/js/min/crayon.min.js?ver=2.7.1'></script>
<script type='text/javascript' src='https://www.lab41.org/wp-content/plugins/ckeditor-for-wordpress/ckeditor/ckeditor.js?t=F7J8&#038;ver=4.5.3.3'></script>
<script type='text/javascript' src='https://www.lab41.org/wp-content/plugins/ckeditor-for-wordpress/includes/ckeditor.utils.js?t=F7J8&#038;ver=4.5.3.3'></script>
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://www.lab41.org/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://www.lab41.org/wp-includes/wlwmanifest.xml" /> 
<link rel='prev' title='A Tour of Sentiment Analysis Techniques: Getting a Baseline for Sunny Side Up' href='https://www.lab41.org/a-tour-of-sentiment-analysis-techniques-getting-a-baseline-for-sunny-side-up/' />
<link rel='next' title='Faster On-Ramp to Deep Learning With Jupyter-driven Docker Containers' href='https://www.lab41.org/faster-on-ramp-to-deep-learning-with-jupyter-driven-docker-containers/' />
<link rel='canonical' href='https://www.lab41.org/anything2vec/' />
<link rel='shortlink' href='https://www.lab41.org/?p=267' />
<style type="text/css" media="print">#wpadminbar { display:none; }</style>
<style type="text/css" media="screen">
	html { margin-top: 32px !important; }
	* html body { margin-top: 32px !important; }
	@media screen and ( max-width: 782px ) {
		html { margin-top: 46px !important; }
		* html body { margin-top: 46px !important; }
	}
</style>
		<link rel="stylesheet" id="custom-css-css" type="text/css" href="https://www.lab41.org/?custom-css=1&#038;csblog=1&#038;cscache=6&#038;csrev=13" />
		  </head>

  
<nav class="mobile-nav">
  <div class="container">
    <a class="mobile-logo" href="/"></a>
    <a class="mobile-nav-btn" href="#"></a>
    <p class="mobile-heading">Gab41</p>
  </div>
</nav>

<nav class="mobile-nav-menu">
  <div class="mobile-nav-menu-header">
    <a class="mobile-nav-header-logo" href="/"><img src="https://www.lab41.org/wp-content/themes/wp20150917/images/mobile-logo-menu.svg"></a>
    <p class="mobile-nav-header-title">Menu <a class="mobile-nav-header-btn" href="#"><img src="https://www.lab41.org/wp-content/themes/wp20150917/images/btn-close-white.svg"></a></p>
  </div>
  <a class="mobile-nav-menu-link" href="/">Home</a>
  <a class="mobile-nav-menu-link " href="/work">Work</a><a class="mobile-nav-menu-link mod-is-active" href="/gab41">Gab41</a><a class="mobile-nav-menu-link " href="/process">Process</a><a class="mobile-nav-menu-link " href="/about">About</a><a class="mobile-nav-menu-link " href="/contact">Contact</a></nav>
  <nav class="tablet-nav">
  <div class="container">
    <div class="tablet-logo">
      <a class="tablet-logo-image" href="/"><img src="https://www.lab41.org/wp-content/themes/wp20150917/images/mobile-logo.svg"></a>
    </div>

    <a class="tablet-nav-link " href="/work">Work</a><a class="tablet-nav-link mod-is-active" href="/gab41">Gab41</a><a class="tablet-nav-link " href="/process">Process</a><a class="tablet-nav-link " href="/about">About</a><a class="tablet-nav-link " href="/contact">Contact</a>    <a class="tablet-nav-link" href="/">Home</a>
  </div>
</nav>

    
  <section class="intro" style="background-image: url(http://www.lab41.org/wp-content/uploads/2015/08/gab41-hero.jpg);">
<a class="intro-logo" href="/" id="logo"></a>
    <div class="intro-menu" id="menu">
  <a class="intro-menu-link " href="/work">Work</a><a class="intro-menu-link mod-is-active" href="/gab41">Gab41</a><a class="intro-menu-link " href="/process">Process</a><a class="intro-menu-link " href="/about">About</a><a class="intro-menu-link " href="/contact">Contact</a></div>

    <div class="intro-wrapper">
      <a href="/gab41"><p class="intro-title-gab41">Gab<span class="intro-title-gab41-red">41</span></p></a>
              <p class="intro-heading intro-heading-red">No. 18 </p>
        <p class="intro-heading">Anything2Vec</p>

          </div>
  </section>


<section class="post container is-white">

      <div class="post-header">
      <div class="post-byline">
        <a href="https://www.lab41.org/author/karln/" title="Posts by Karl Ni" class="url fn" rel="author">Karl Ni</a>        <p class="article-date">November 2015</p>
      </div>

      <div class="post-top-links">
        <a onclick="window.print()" class="post-top-link pdf">PDF</a>
        <a onclick="window.print()" class="post-top-link print">Print</a>
      </div>
    </div>

    <h3>2Vec or Not 2Vec?</h3>
<p>This might be old news to you, but if you're considering the use of word embeddings, our suggestion: just take the plunge. We've read a "few" studies documenting their effectiveness, not the least of which is our personal favorite:</p>
<blockquote><p>"This paper is summarized best by its own statement, which should win it the award for most honest paper ever: "...we set out to conduct this study because we were annoyed by the triumphalist overtones often surrounding [neural network embeddings], despite the almost complete lack of a proper comparison.... Our secret wish was to discover that it is all hype... Instead, we found that the [embeddings] are so good that, while the triumphalist overtones still sound excessive, there are very good reasons to switch to the new architecture."</p></blockquote>
<p><a href="http://69.195.124.161/~aclwebor/anthology/P/P14/P14-1023.pdf">Baroni, Dinu, &amp; Kruszewski</a> are a bit dramatic, but they get the point across. You may not be able to explain why (though we'll try, here), but embeddings sure done work good. And as the most popular word embedding algorithm, not many techniques have caught fire as much as Tomas Mikolov's <em>word2vec</em> algorithm.</p>
<p>In 2013, <em><a href="http://arxiv.org/pdf/1310.4546.pdf">word2vec</a></em> made waves in the neural network world. The <a href="https://code.google.com/p/word2vec/">code</a> was readable and really fast (multi-threaded C code), helping it achieve wide adoption. Since then, Google archived the code (though it's still available), and Mikolov changed companies. Still, that didn't stop the momentum, and there's been a glut of implementations on platforms and software packages like Python, Scala (and <a href="https://spark.apache.org/docs/latest/mllib-feature-extraction.html#word2vec">ML-Lib in Spark</a>), <a href="http://deeplearning4j.org/word2vec.html">DL4J</a>, <a href="https://radimrehurek.com/gensim/models/word2vec.html">gensim</a>, and <a href="http://lmgtfy.com/?q=word2vec+implementation">maybe a zillion more</a>, to make it fit into the everyday man's NLP toolbox.</p>
<p>In fact, <em>word2vec</em> has been applied to not-so-obvious applications: twitter network analysis, network traffic analytics, named entity association, and the list goes on. But the 2Vec craze doesn't end with word embeddings. If you've been to CVPR 2015 or participated in Baylearn 2015, you'd know that <a href="https://www.reddit.com/r/MachineLearning/comments/3e34fz/video_yann_lecun_at_cvpr_2015_whats_wrong_with/">Yann LeCun is bent on embedding the world</a>, i.e. "World2Vec" (make sure Google doesn't autocorrect you when you search for it.) The World2Vec pitch in the linked video starts at 50:24, but the LeCunian entertainment is present throughout the video.</p>
<p>LeCun's brand of enthusiasm might make you doubt the extravagant mantra (that vector space can, but that's not just crazy talk, since Hinton's group has similar ideas. And yes, we take it literally when we say ideas: the group (Ryan Kiros, primarily) has, in fact, implemented a type of "idea-2-vec" in recent Q&amp;A work, which is open on <a href="https://github.com/ryankiros/skip-thoughts">Git</a>. They call it Skip-Thought Vectors, which is synonymously known as <em>sent2vec</em>. Our personal favorite from "<a href="https://github.com/kjw0612/awesome-deep-vision">awesome deep vision</a>" is where <a href="https://github.com/kjw0612/awesome-deep-vision#question-answering">Baidu's chatbot</a> claims to be able to fool you into thinking you're talking to a human.</p>
<p>As an aside, we're "meh" on this. Claims regarding chatbots being Turing Complete have always been suspect. That's a whole other blog post (which we'll write later, time permitting, but Google for NPR's Fresh Air's take on it.) It really depends on the situation. For example, a statue could pass the Turing test...if a dog administered it:</p>
<p><a href="http://www.lab41.org/wp-content/uploads/2015/10/dogturing.gif"><img class="size-full wp-image-291 aligncenter" src="https://www.lab41.org/wp-content/uploads/2015/10/dogturing.gif" alt="dogturing" width="240" height="225" /></a>(<a href="http://www.npr.org/sections/13.7/2014/06/13/321755270/the-turing-test-is-not-what-you-think-it-is">Photo GIF of a dog and Alan Turing</a>)</p>
<p>Sorry, we're getting carried away. Anyway, so why this blog post? Why not read the papers? After talking with several colleagues and friends spanning multiple countries, as it turns out, not a lot of people know why it works and why it's called a neural network. They had a good grasp of what was happening, but formalizing it in deep learning frameworks was difficult and the papers weren't helping.</p>
<p>Really, the concepts as explained are surprisingly simple. But, if you're like us, who jumped on the DL-train to Bandwagon-Town, we like writing Keras/Theano/Torch/Caffe layers to fit into existing and new architectures. And although the DL-train is full-steam ahead and doesn't often stop for explanations, we feel like this one deserves a deeper look.</p>
<h3>What We're Familiar With</h3>
<p>There are a lot of DL packages out there, and nearly all of them have a good suite of objective/cost functions. For the uninitiated, objective/cost functions are those equations you're trying to minimize, and they usually follow some logical principle like, make the error between what we predict and the truth as small as possible. Look at the Keras toolbox's "Available Objectives" for the most commonly used ones, you'll see:</p>
<p><a href="http://www.lab41.org/wp-content/uploads/2015/10/Screen-Shot-2015-10-21-at-10.34.34-AM.png"><img class="aligncenter wp-image-277 size-large" src="https://www.lab41.org/wp-content/uploads/2015/10/Screen-Shot-2015-10-21-at-10.34.34-AM-1024x841.png" alt="Screen Shot 2015-10-21 at 10.34.34 AM" width="1024px" height="auto" /></a>(Taken from the <a href="http://keras.io/objectives/">Keras documentation website</a>.)</p>
<p>If you've been involved in the ImageNet competition, you probably love categorical cross-entropy so much you want to marry it. In this blog post, we're going to step away from that function. Why? Because chances are, you're using a <a href="https://en.wikipedia.org/wiki/Softmax_function">softmax layer</a> before optimizing, normalizing the output to a posterior probability. That's nice, but only where you know your input relates to exactly one of the classes in the set of candidates. In the case of text prediction and vector space construction (the key idea of <em>word2vec</em>), where a predicted value should relate to multiple labels, we prefer binary crossentropy (and heck, even, MSE). That optimization (according to Hinton) is written as:</p>
<p><a href="http://www.lab41.org/wp-content/uploads/2015/11/Screen-Shot-2015-11-02-at-3.57.45-PM.png"><img class="aligncenter wp-image-329 size-full" src="https://www.lab41.org/wp-content/uploads/2015/11/Screen-Shot-2015-11-02-at-3.57.45-PM.png" alt="Screen Shot 2015-11-02 at 3.57.45 PM" width="453" height="64" /></a></p>
<p>Here, the y's are the true outputs and h(x) is the output of the neural network that you're building. We'll try not to get too math-y, and at this point in time, you're probably asking, what's our point? Well, not a lot of people know that <em>word2vec</em> is precisely a 2-layer conventional neural network with a slightly modified binary cross-entropy optimization. If you can visualize that, there's no need to read further. Otherwise, we're going to show you that you can make <em>word2vec</em> out of all the traditional objective function parts and layers from your toolboxes with some slight modifications.</p>
<h3>The Rub</h3>
<p>Chances are, if you've read anything about <em>word2vec</em>, you've seen something that looks like this:</p>
<p><a href="http://www.lab41.org/wp-content/uploads/2015/10/sentiment_01_large.png"><img class="wp-image-268 size-full aligncenter" src="https://www.lab41.org/wp-content/uploads/2015/10/sentiment_01_large.png" alt="sentiment_01_large" width="551" height="324" /></a>(Taken from <a href="http://arxiv.org/pdf/1310.4546.pdf">Mikolov's arXiv paper</a>.)</p>
<p>This is great for explaining out <em>word2vec</em> works (look up anything written by Chris Manning). Unfortunately, these diagrams, IMHO, do us a disservice because they obscure how they relate to conventional neural networks. Also unfortunate is that the people call this "deep learning", because doing so, again IMHO, makes the term lose some of its original meaning. I'd call vector spaces learning <em>wide learning</em> rather than deep learning.</p>
<p>Mikolov's Word2Vec runs on something called negative sampling, a generalization of <a href="http://www.jmlr.org/proceedings/papers/v9/gutmann10a/gutmann10a.pdf">Noise Contrastive Estimation</a> (NCE). It's a math-y paper, but worth the read if you've got the time and patience. One thing that's glossed over is that NCE can approximate the minimization of the log probability of the <em>softmax</em>. As it turns out, instead, negative sampling approximates the binary cross-entropy cost function (the log loss for some of you).</p>
<p>Negative sampling can be expressed by the below equation (taken directly from Mikolov's paper):</p>
<p><a href="http://www.lab41.org/wp-content/uploads/2015/11/Screen-Shot-2015-11-02-at-4.44.32-PM.png"><img class="aligncenter wp-image-334 size-full" src="https://www.lab41.org/wp-content/uploads/2015/11/Screen-Shot-2015-11-02-at-4.44.32-PM.png" alt="Screen Shot 2015-11-02 at 4.44.32 PM" width="501" height="76" /></a></p>
<p>Here, <em>v<sub>w<sub>O</sub></sub></em> is the output word vector (relating to <em>w<sub>O</sub></em>), <em>v<sub>w<sub>I</sub></sub></em> is the input vector (relating to <em>w<sub>I</sub></em>), and we are drawing word <em>w<sub>n</sub></em> from the negative distribution of words: <em>P<sub>n</sub>(w)</em>. We're summing over only a select number of negative examples (i.e., <em>n</em> goes from 1 to a small number...let's say 10). To build some intuition, it might be straightforward to see how maximizing this function produces the vectors that you want (in both input and output spaces).</p>
<ul>
<li>The first term [highlight]: maximize the inner product of your input vector and an output vector.</li>
<li>The second term: simultaneously minimize the inner product of your input vector and a bunch of randomly sampled vectors.</li>
</ul>
<p>Easy, right? No? It's a bunch of fancy letters just to say that you're pushing words close to their context and pulling them away from the background distribution. Assuming that we are already taking samples from the background distribution (i.e., getting rid of the expectation notation), we can just sum the correlation of a randomly sampled vector with the input vector. If we say that <em>y</em> is an indicator as to whether or not a word is in the context of another word (1 = in context, 0 = not in context), then the value for <em>y</em> (let's call it <em>y<sub>OI</sub></em>) relating to the output (denoted by subscript <em>O</em>) and input vector (denoted by subscript <em>I</em>) is equal to one. Likewise, the value for <em>y<sub>nI</sub></em> relating to a negative sample (denoted by subscript <em>n</em>) and the input vector (again denoted by <em>I</em>) is zero. Then, after some derivations, the cost function looks suspiciously familiar:</p>
<p><a href="http://www.lab41.org/wp-content/uploads/2015/11/Screen-Shot-2015-11-02-at-4.43.32-PM.png"><img class="aligncenter wp-image-333 size-full" src="https://www.lab41.org/wp-content/uploads/2015/11/Screen-Shot-2015-11-02-at-4.43.32-PM.png" alt="Screen Shot 2015-11-02 at 4.43.32 PM" width="602" height="252" /></a></p>
<p>Pay attention to that last line; not only did we introduce the binary <em>y</em> vector, but we've also introduced this <em>s<sub>i </sub></em>value, which stands for sample <em>i</em>. It's one or zero depending on if you're actually using this sample. That is, if your negative sample includes the label category <em>i</em>.</p>
<p>So look at this last line and look at the binary cross-entropy function equation in the previous section. The only difference between the <em>word2vec </em>cost function and binary cross-entropy is that you're doing negative sampling: the <em>s<sub>i</sub></em>, which effectively chooses a subset of the samples when <em>y=0</em>. That's what that <em>s<sub>i</sub></em> term is in there for. It's really just saying, I don't want to take every word vector that's not related to my input word vector into account...that would be too expensive. No, let's just take the one that's the most relevant.</p>
<h3>Redistributing Distributed Learning</h3>
<p>That's the cost function, now the architecture. Let's say that we have a vocabulary, and instead of drawing the vectors individually, let's draw them all together. We can collect a whole bunch of vectors of words and assemble them into a matrix. Let's call this matrix <em>V<sub>I</sub></em>.</p>
<p><a href="http://www.lab41.org/wp-content/uploads/2015/10/Screen-Shot-2015-10-21-at-5.17.11-PM.png"><img class="size-medium wp-image-283 aligncenter" src="https://www.lab41.org/wp-content/uploads/2015/10/Screen-Shot-2015-10-21-at-5.17.11-PM-300x142.png" alt="Screen Shot 2015-10-21 at 5.17.11 PM" width="300" height="auto" /></a>(Imagine that each column is a word vector. In this case, they are all the input word vectors.)</p>
<p>On the flip side, you remember the "one-hot" encoding vector idea? If the <em>ith</em> word in the dictionary is being used, then the <em>ith</em> element of a one hot vector <strong>x</strong><em><sub>I</sub></em> is nonzero:</p>
<p><a href="http://www.lab41.org/wp-content/uploads/2015/10/Screen-Shot-2015-10-21-at-4.59.17-PM.png"><img class="size-medium wp-image-280 aligncenter" src="https://www.lab41.org/wp-content/uploads/2015/10/Screen-Shot-2015-10-21-at-4.59.17-PM-300x26.png" alt="Screen Shot 2015-10-21 at 4.59.17 PM" width="300" height="auto" /></a></p>
<p>Let's say we're looking at the <em>ith</em> word. Then, that means we want to optimize for the <em>ith</em> vector. To extract that vector from the matrix <em>Vi</em> from in a linear algebraic sense, it's simply a matrix multiplication: <em>v<sub>w<sub>I</sub></sub></em>=<em>V<sub>I </sub></em><strong>x</strong><em><sub>I</sub></em>. If you need a picture, take a gander at this:</p>
<p><a href="http://www.lab41.org/wp-content/uploads/2015/10/Screen-Shot-2015-10-21-at-5.20.26-PM.png"><img class="size-medium wp-image-284 aligncenter" src="https://www.lab41.org/wp-content/uploads/2015/10/Screen-Shot-2015-10-21-at-5.20.26-PM-300x191.png" alt="Screen Shot 2015-10-21 at 5.20.26 PM" width="300" height="auto" /></a></p>
<p>Recall the objective function, where we're multiplying the vector input with multiple output vectors. Let's say, for example, I want to multiply two output vectors with the input vectors. So similarly, let's select the output vectors, and multiply. Visually, this looks like:</p>
<p><a href="http://www.lab41.org/wp-content/uploads/2015/10/Screen-Shot-2015-10-30-at-9.04.52-AM.png"><img class="size-medium wp-image-303 aligncenter" src="https://www.lab41.org/wp-content/uploads/2015/10/Screen-Shot-2015-10-30-at-9.04.52-AM-300x161.png" alt="Screen Shot 2015-10-30 at 9.04.52 AM" width="300" height="auto" /></a></p>
<p>which is the same as:</p>
<p><a href="http://www.lab41.org/wp-content/uploads/2015/10/Screen-Shot-2015-10-30-at-2.33.01-PM.png"><img class="size-medium wp-image-324 aligncenter" src="https://www.lab41.org/wp-content/uploads/2015/10/Screen-Shot-2015-10-30-at-2.33.01-PM-300x105.png" alt="Screen Shot 2015-10-30 at 2.33.01 PM" width="300" height="auto" /></a></p>
<p>Let's turn the diagram 90 degrees, and put a cherry on the top by adding a sigmoid nonlinearity function.</p>
<p style="text-align: center"><a href="http://www.lab41.org/wp-content/uploads/2015/11/Screen-Shot-2015-11-02-at-5.03.31-PM.png"><img class="alignnone size-medium wp-image-337" src="https://www.lab41.org/wp-content/uploads/2015/11/Screen-Shot-2015-11-02-at-5.03.31-PM-210x300.png" alt="Screen Shot 2015-11-02 at 5.03.31 PM" width="210" height="300" /></a></p>
<p>So, if I were taking the sum of all the outputs, this would just look like:</p>
<p><a href="http://www.lab41.org/wp-content/uploads/2015/11/Screen-Shot-2015-11-02-at-4.48.57-PM.png"><img class="aligncenter wp-image-335 size-full" src="https://www.lab41.org/wp-content/uploads/2015/11/Screen-Shot-2015-11-02-at-4.48.57-PM.png" alt="Screen Shot 2015-11-02 at 4.48.57 PM" width="423" height="80" /></a></p>
<p>This should be more what you're used to, though if you implement it like this with traditional tools, it's probably really inefficient since you're using matrix-vector multiplications rather than Mikolov's vector-vector multiplications. Depending on how many vectors you use for negative sampling, you really only need to update a few vectors every iteration. So, obviously, you won't want to use the BLAS library on the entire matrix vector multiplication, but if you plug in our equation from the previous section in, you'll see that this is exactly your run of the mill neural network implementation, just tons more efficient.</p>
<p>As a whole, current implementations (especially the multi-threaded) are cool because you're sampling on the foreground and background distribution, and so in the limit, you'll converge to a solution that places vectors based on their co-occurrence in text. There's also a random component to it that could potentially get you out of local minima, given enough iterations. We're real fans.</p>
<h3>What did we just say?</h3>
<p>There you have it. The <em>word2vec</em> architecture is a neural network with two parameter matrices followed by a sigmoid activation function. It's optimized by a binary cross-entropy cost function, using random negative sampling. If you want some code, feel free to get it at our <a href="https://github.com/Lab41">Lab41 Github page</a>.</p>
<p>&nbsp;</p>
    
    <p></p>

      
</section>

  <section class="pagination container">
    <div class="pagination-wrapper">

          <a class="pagination-button-left" href="https://www.lab41.org/a-tour-of-sentiment-analysis-techniques-getting-a-baseline-for-sunny-side-up/">Older</a>
    
          <a class="pagination-button-right" href="https://www.lab41.org/faster-on-ramp-to-deep-learning-with-jupyter-driven-docker-containers/">Newer</a>
    
    </div>
  </section>



<section class="cta-dark cta-41" style="background-image: url(https://www.lab41.org/wp-content/uploads/2015/08/gab41-hero.jpg);">
  <div class="container">
    <hr class="cta-hr"></hr>
    <p class="cta-title">Process</p>
    <p class="cta-heading">Get more insight into how we work</p>
    <p class="cta-detail mod-light mod-inline"></p>
    <a class="button" href="/process">Lets go</a>
  </div>
</section>


  
  <footer class="footer container is-white">
  <a class="footer-link" href="/"><img src="https://www.lab41.org/wp-content/themes/wp20150917/images/footer-logo.svg"></a>
  <p class="footer-link">
    Contact us at
    <a class="footer-link-red" href="/contact">
      info@lab41.org
    </a>
  </p>
  <p class="footer-link">&copy; 2016<br/><br/> In-Q-Tel</p>

  <div class="footer-bottom-link">
    <a class="footer-social-link" href="https://www.iqt.org/" target="_blank">
      <img width="44" src="https://www.lab41.org/wp-content/themes/wp20150917/images/footer-icon-iqt.png">
    </a>
    <a class="footer-social-link" href="https://try.lab41.org" target="_blank">
      <img src="https://www.lab41.org/wp-content/themes/wp20150917/images/footer-icon-try-41.svg">
    </a>
    <a class="footer-social-link" href="https://github.com/lab41" target="_blank">
      <img src="https://www.lab41.org/wp-content/themes/wp20150917/images/footer-icon-github.svg">
    </a>
  </div>
</footer>
  <!-- loading scripts -->

<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://www.lab41.org/wp-content/themes/wp20150917/js/site.js"></script>
<script src="https://www.lab41.org/wp-content/themes/wp20150917/includes/blog/google-analytics.js"></script>



<!-- END loading scripts -->



  <script type='text/javascript' src='https://www.lab41.org/wp-includes/js/admin-bar.min.js?ver=4.3.2'></script>
<script type='text/javascript' src='https://www.lab41.org/wp-content/plugins/contact-form-7/includes/js/jquery.form.min.js?ver=3.51.0-2014.06.20'></script>
<script type='text/javascript'>
/* <![CDATA[ */
var _wpcf7 = {"loaderUrl":"https:\/\/www.lab41.org\/wp-content\/plugins\/contact-form-7\/images\/ajax-loader.gif","sending":"Sending ...","cached":"1"};
/* ]]> */
</script>
<script type='text/javascript' src='https://www.lab41.org/wp-content/plugins/contact-form-7/includes/js/scripts.js?ver=4.3'></script>
		<div id="wpadminbar" class="nojq nojs">
							<a class="screen-reader-shortcut" href="#wp-toolbar" tabindex="1">Skip to toolbar</a>
						<div class="quicklinks" id="wp-toolbar" role="navigation" aria-label="Toolbar" tabindex="0">
				<ul id="wp-admin-bar-root-default" class="ab-top-menu">
		<li id="wp-admin-bar-wp-logo" class="menupop"><a class="ab-item"  aria-haspopup="true" href="https://www.lab41.org/wp-admin/about.php"><span class="ab-icon"></span><span class="screen-reader-text">About WordPress</span></a><div class="ab-sub-wrapper"><ul id="wp-admin-bar-wp-logo-default" class="ab-submenu">
		<li id="wp-admin-bar-about"><a class="ab-item"  href="https://www.lab41.org/wp-admin/about.php">About WordPress</a>		</li></ul><ul id="wp-admin-bar-wp-logo-external" class="ab-sub-secondary ab-submenu">
		<li id="wp-admin-bar-wporg"><a class="ab-item"  href="https://wordpress.org/">WordPress.org</a>		</li>
		<li id="wp-admin-bar-documentation"><a class="ab-item"  href="https://codex.wordpress.org/">Documentation</a>		</li>
		<li id="wp-admin-bar-support-forums"><a class="ab-item"  href="https://wordpress.org/support/">Support Forums</a>		</li>
		<li id="wp-admin-bar-feedback"><a class="ab-item"  href="https://wordpress.org/support/forum/requests-and-feedback">Feedback</a>		</li></ul></div>		</li>
		<li id="wp-admin-bar-my-sites" class="menupop"><a class="ab-item"  aria-haspopup="true" href="https://www.lab41.org/wp-admin/my-sites.php">My Sites</a><div class="ab-sub-wrapper"><ul id="wp-admin-bar-my-sites-list" class="ab-submenu">
		<li id="wp-admin-bar-blog-1" class="menupop"><a class="ab-item"  aria-haspopup="true" href="https://www.lab41.org/wp-admin/"><div class="blavatar"></div>Lab41</a><div class="ab-sub-wrapper"><ul id="wp-admin-bar-blog-1-default" class="ab-submenu">
		<li id="wp-admin-bar-blog-1-d"><a class="ab-item"  href="https://www.lab41.org/wp-admin/">Dashboard</a>		</li>
		<li id="wp-admin-bar-blog-1-n"><a class="ab-item"  href="https://www.lab41.org/wp-admin/post-new.php">New Post</a>		</li>
		<li id="wp-admin-bar-blog-1-c"><a class="ab-item"  href="https://www.lab41.org/wp-admin/edit-comments.php">Manage Comments</a>		</li>
		<li id="wp-admin-bar-blog-1-v"><a class="ab-item"  href="https://www.lab41.org/">Visit Site</a>		</li></ul></div>		</li></ul></div>		</li>
		<li id="wp-admin-bar-site-name" class="menupop"><a class="ab-item"  aria-haspopup="true" href="https://www.lab41.org/wp-admin/">Lab41</a><div class="ab-sub-wrapper"><ul id="wp-admin-bar-site-name-default" class="ab-submenu">
		<li id="wp-admin-bar-dashboard"><a class="ab-item"  href="https://www.lab41.org/wp-admin/">Dashboard</a>		</li></ul></div>		</li>
		<li id="wp-admin-bar-comments"><a class="ab-item"  href="https://www.lab41.org/wp-admin/edit-comments.php" title="13 comments awaiting moderation"><span class="ab-icon"></span><span id="ab-awaiting-mod" class="ab-label awaiting-mod pending-count count-13">13</span></a>		</li>
		<li id="wp-admin-bar-new-content" class="menupop"><a class="ab-item"  aria-haspopup="true" href="https://www.lab41.org/wp-admin/post-new.php"><span class="ab-icon"></span><span class="ab-label">New</span></a><div class="ab-sub-wrapper"><ul id="wp-admin-bar-new-content-default" class="ab-submenu">
		<li id="wp-admin-bar-new-post"><a class="ab-item"  href="https://www.lab41.org/wp-admin/post-new.php">Post</a>		</li>
		<li id="wp-admin-bar-new-media"><a class="ab-item"  href="https://www.lab41.org/wp-admin/media-new.php">Media</a>		</li></ul></div>		</li></ul><ul id="wp-admin-bar-top-secondary" class="ab-top-secondary ab-top-menu">
		<li id="wp-admin-bar-search" class="admin-bar-search"><div class="ab-item ab-empty-item" tabindex="-1"><form action="https://www.lab41.org/" method="get" id="adminbarsearch"><input class="adminbar-input" name="s" id="adminbar-search" type="text" value="" maxlength="150" /><label for="adminbar-search" class="screen-reader-text">Search</label><input type="submit" class="adminbar-button" value="Search"/></form></div>		</li>
		<li id="wp-admin-bar-my-account" class="menupop with-avatar"><a class="ab-item"  aria-haspopup="true" href="https://www.lab41.org/wp-admin/profile.php">Howdy, Karl Ni<img alt='' src='https://secure.gravatar.com/avatar/ee3e5ea9c333ba492c8ffc3b7686382a?s=26&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/ee3e5ea9c333ba492c8ffc3b7686382a?s=52&amp;d=mm&amp;r=g 2x' class='avatar avatar-26 photo' height='26' width='26' /></a><div class="ab-sub-wrapper"><ul id="wp-admin-bar-user-actions" class="ab-submenu">
		<li id="wp-admin-bar-user-info"><a class="ab-item" tabindex="-1" href="https://www.lab41.org/wp-admin/profile.php"><img alt='' src='https://secure.gravatar.com/avatar/ee3e5ea9c333ba492c8ffc3b7686382a?s=64&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/ee3e5ea9c333ba492c8ffc3b7686382a?s=128&amp;d=mm&amp;r=g 2x' class='avatar avatar-64 photo' height='64' width='64' /><span class='display-name'>Karl Ni</span><span class='username'>karln</span></a>		</li>
		<li id="wp-admin-bar-edit-profile"><a class="ab-item"  href="https://www.lab41.org/wp-admin/profile.php">Edit My Profile</a>		</li>
		<li id="wp-admin-bar-logout"><a class="ab-item"  href="https://www.lab41.org/wp-login.php?action=logout&#038;_wpnonce=b82b3a7950">Log Out</a>		</li></ul></div>		</li></ul>			</div>
						<a class="screen-reader-shortcut" href="https://www.lab41.org/wp-login.php?action=logout&#038;_wpnonce=b82b3a7950">Log Out</a>
					</div>

		</body>
</html>
